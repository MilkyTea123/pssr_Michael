{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9zNGvape2-I"
      },
      "source": [
        "# **Point Scanning Super Resolution (PSSR) - Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4-r1gE7Iamv"
      },
      "source": [
        "# **1. Preparation: Set the Runtime type and mount your Google Drive**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5_nSag2fU94"
      },
      "source": [
        "## **1.1. Set the Runtime type**\n",
        "---\n",
        "\n",
        "<font size = 4>Go to **Runtime -> Change the Runtime type**\n",
        "\n",
        "<font size = 4>**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n",
        "\n",
        "<font size = 4>**Accelator: GPU** *(Graphics processing unit (GPU)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDhmUgqCStlm",
        "outputId": "24a0c31d-4ca9-4eaf-eff3-ee1b8f51245f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 16:47:12.202774: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You do not have GPU access.\n",
            "Did you change your runtime ?\n",
            "If the runtime settings are correct then Google did not allocate GPU to your session\n",
            "Expect slow performance. To access GPU try reconnecting later\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 16:47:13.428598: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 16091977336307693434\n",
              " xla_global_id: -1]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Run this cell to check if you have GPU access\n",
        "\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name()=='':\n",
        "  print('You do not have GPU access.') \n",
        "  print('Did you change your runtime ?') \n",
        "  print('If the runtime settings are correct then Google did not allocate GPU to your session')\n",
        "  print('Expect slow performance. To access GPU try reconnecting later')\n",
        "else:\n",
        "  print('You have GPU access')\n",
        "\n",
        "from tensorflow.python.client import device_lib \n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqBTeLaImnU"
      },
      "source": [
        "## **1.2. Mount your Google Drive**\n",
        "---\n",
        "<font size = 4> To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n",
        "\n",
        "<font size = 4> Play the cell below to mount your Google Drive and follow the link. In the new browser window, select your drive and select 'Allow', copy the code, paste into the cell and press enter. This will give Colab access to the data on the drive. \n",
        "\n",
        "<font size = 4> Once this is done, your data are available in the **Files** tab on the top left of notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TkQcROufgwL"
      },
      "source": [
        "## **1.3. Install PSSR and dependencies**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS7lCdiQf_0T"
      },
      "source": [
        "## **1.4. Specify your working folder - need your input**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vmx810jDXTbc"
      },
      "outputs": [],
      "source": [
        "root_path = \"/content/gdrive/MyDrive/PSSR-32bit\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMetHM56gMkf"
      },
      "source": [
        "# **2. PSSR - Get to know your training data**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vETWgkZ5v4dm"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'root_path' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/gigo/pssr_Michael/Base_PSSR_01_32bitTS.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gigo/pssr_Michael/Base_PSSR_01_32bitTS.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gigo/pssr_Michael/Base_PSSR_01_32bitTS.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m1\u001b[39m, root_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gigo/pssr_Michael/Base_PSSR_01_32bitTS.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfastai\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gigo/pssr_Michael/Base_PSSR_01_32bitTS.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfastai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvision\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'root_path' is not defined"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(1, root_path)\n",
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from fastcore.script import *\n",
        "from utils import *\n",
        "from pathlib import Path\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from time import sleep\n",
        "import shutil\n",
        "import PIL\n",
        "import czifile\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 99999999999999"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCG3IlyEjzBa"
      },
      "source": [
        "## **2.1. Specify your datasource - need your input**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNZ7jTg7E5XK"
      },
      "outputs": [],
      "source": [
        "sources = [root_path + '/32bitTS'] #must be in form of array\n",
        "output_file = 'mod_test.csv'\n",
        "only = 'mod_test'\n",
        "skip = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmTld6FTyqbE"
      },
      "outputs": [],
      "source": [
        "src_dirs = []\n",
        "for src in sources:\n",
        "    sub_fldrs = subfolders(Path(src))\n",
        "    if skip: src_dirs += [fldr for fldr in sub_fldrs if fldr.stem not in skip]\n",
        "    elif only: src_dirs += [fldr for fldr in sub_fldrs if fldr.stem in only]\n",
        "    else: src_dirs += sub_fldrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x094J7X2zIlb"
      },
      "outputs": [],
      "source": [
        "#@title process_czi()\n",
        "def process_czi(item, category, mode):\n",
        "#This function only takes the first channel of the czi files\n",
        "#since those are the only mitotracker channels\n",
        "    tif_srcs = []\n",
        "    base_name = item.stem\n",
        "    with czifile.CziFile(item) as czi_f:\n",
        "        data = czi_f.asarray()\n",
        "        axes, shape = get_czi_shape_info(czi_f)\n",
        "        channels = shape['C']\n",
        "        depths = shape['Z']\n",
        "        times = shape['T']\n",
        "        #times = min(times, 30) #ONLY USE FIRST 30 frames\n",
        "        x,y = shape['X'], shape['Y']\n",
        "\n",
        "        mid_depth = depths // 2\n",
        "        depth_range = range(max(0,mid_depth-2), min(depths, mid_depth+2))\n",
        "        is_multi = (times > 1) or (depths > 1)\n",
        "\n",
        "        data = czi_f.asarray()\n",
        "        all_rmax = data.max()\n",
        "        all_mi, all_ma = np.percentile(data, [2,99.99])\n",
        "\n",
        "        dtype = data.dtype\n",
        "        #for channel in range(channels): #if other channels are needed, use this line\n",
        "        for channel in range(0,1):\n",
        "            for z in depth_range:\n",
        "                for t in range(times):\n",
        "                    idx = build_index(\n",
        "                        axes, {\n",
        "                            'T': t,\n",
        "                            'C': channel,\n",
        "                            'Z': z,\n",
        "                            'X': slice(0, x),\n",
        "                            'Y': slice(0, y)\n",
        "                        })\n",
        "                    img = data[idx]\n",
        "                    mi, ma = np.percentile(img, [2,99.99])\n",
        "                    if dtype == np.uint8: rmax = 255.\n",
        "                    else: rmax = img.max()\n",
        "                    tif_srcs.append({'fn': item, 'ftype': 'czi', 'multi':int(is_multi), 'category': category, 'dsplit': mode,\n",
        "                                     'uint8': dtype == np.uint8, 'mi': mi, 'ma': ma, 'rmax': rmax,\n",
        "                                     'all_rmax': all_rmax, 'all_mi': all_mi, 'all_ma': all_ma,\n",
        "                                     'mean': img.mean(), 'sd': img.std(),\n",
        "                                     'nc': channels, 'nz': depths, 'nt': times,\n",
        "                                     'z': z, 't': t, 'c':channel, 'x': x, 'y': y})\n",
        "    return tif_srcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szuxHh1XFnQs"
      },
      "outputs": [],
      "source": [
        "def is_live(item):\n",
        "    return item.parent.parts[-3] == 'live'\n",
        "\n",
        "def process_tif(item, category, mode):\n",
        "    tif_srcs = []\n",
        "    img = PIL.Image.open(item)\n",
        "    n_frames = img.n_frames\n",
        "    x,y = img.size\n",
        "    is_multi = n_frames > 1\n",
        "    #n_frames = min(n_frames, 30) #ONLY USE FIRST 30 frames\n",
        "\n",
        "    data = []\n",
        "    for n in range(n_frames):\n",
        "        img.seek(n)\n",
        "        img.load()\n",
        "        img_data = np.array(img)\n",
        "        data.append(img_data)\n",
        "\n",
        "    data = np.stack(data)\n",
        "    all_rmax = data.max()\n",
        "    all_mi, all_ma = np.percentile(data, [2,99.99])\n",
        "\n",
        "    for n in range(n_frames):\n",
        "        img_data = data[n]\n",
        "        dtype = img_data.dtype\n",
        "        mi, ma = np.percentile(img_data, [2,99.99])\n",
        "        if dtype == np.uint8: rmax = 255.\n",
        "        else: rmax = img_data.max()\n",
        "        if is_live(item):\n",
        "            t, z = n, 0\n",
        "            nt, nz = n_frames, 1\n",
        "        else:\n",
        "            t, z = 0, n\n",
        "            nt, nz = 1, n_frames\n",
        "        \n",
        "        print(item)\n",
        "\n",
        "        tif_srcs.append({'fn': item, 'ftype': 'tif', 'multi':int(is_multi), 'category': category, 'dsplit': mode,\n",
        "                         'uint8': dtype==np.uint8, 'mi': mi, 'ma': ma, 'rmax': rmax,\n",
        "                         'all_rmax': all_rmax, 'all_mi': all_mi, 'all_ma': all_ma,\n",
        "                         'mean': img_data.mean(), 'sd': img_data.std(),\n",
        "                         'nc': 1, 'nz': nz, 'nt': nt,\n",
        "                         'z': z, 't': t, 'c':0, 'x': x, 'y': y})\n",
        "    return tif_srcs\n",
        "\n",
        "def process_unk(item, category, mode):\n",
        "    print(f\"**** Unknown: {item}\")\n",
        "    return []\n",
        "\n",
        "def process_item(item, category, mode):\n",
        "    try:\n",
        "        if mode == 'test': return []\n",
        "        else:\n",
        "            item_map = {\n",
        "                '.tif': process_tif,\n",
        "                '.tiff': process_tif,\n",
        "                '.czi': process_czi,\n",
        "            }\n",
        "            map_f = item_map.get(item.suffix, process_unk)\n",
        "            return map_f(item, category, mode)\n",
        "    except Exception as ex:\n",
        "        print(f'err procesing: {item}')\n",
        "        print(ex)\n",
        "        return []\n",
        "\n",
        "def build_tifs(src, mbar=None):\n",
        "    tif_srcs = []\n",
        "    for mode in ['train', 'valid', 'test']:\n",
        "        live = src.parent.parts[-1] == 'live'\n",
        "        src_dir = src / mode\n",
        "        category = src.stem\n",
        "        items = list(src_dir.iterdir()) if src_dir.exists() else []\n",
        "        if items:\n",
        "            for p in progress_bar(items, parent=mbar):\n",
        "                mbar.child.comment = mode\n",
        "                tif_srcs += process_item(p, category=category, mode=mode)\n",
        "    return tif_srcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "o7w1fzWrO5-v",
        "outputId": "ddf9c561-6ec6-4e99-f333-b2caa8c2410d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "process mod_test"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "process mod_test\n",
            "/content/gdrive/MyDrive/PSSR-32bit/32bitTS/mod_test/train/TS0006.tif\n",
            "/content/gdrive/MyDrive/PSSR-32bit/32bitTS/mod_test/valid/TS0014.tif\n"
          ]
        }
      ],
      "source": [
        "#pull metadata from datasources\n",
        "mbar = master_bar(src_dirs)\n",
        "tif_srcs = []\n",
        "for src in mbar:\n",
        "    mbar.write(f'process {src.stem}')\n",
        "    tif_srcs += build_tifs(src, mbar=mbar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3UXIgrDn8bC6",
        "outputId": "3ea24c78-59da-4e36-d79a-1f72a4cfe7c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/PSSR-32bit/mod_test.csv'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#save csv to disk\n",
        "tif_src_df = pd.DataFrame(tif_srcs)\n",
        "tif_src_df[['category','dsplit','multi','ftype','uint8','mean','sd','all_rmax','all_mi','all_ma','mi','ma','rmax','nc','nz','nt','c','z','t','x','y','fn']].to_csv(output_file, header=True, index=False)\n",
        "shutil.move(output_file, f'{root_path}/{output_file}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pssrMichael",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e8299560a4fa47ee6a550bbeda4e8a1b4b006c163be4a9e8a3df50218eaf08eb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
