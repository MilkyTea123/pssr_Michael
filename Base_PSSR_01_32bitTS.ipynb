{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9zNGvape2-I"
      },
      "source": [
        "# **Point Scanning Super Resolution (PSSR) - Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4-r1gE7Iamv"
      },
      "source": [
        "# **1. Preparation: Set the Runtime type and mount your Google Drive**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5_nSag2fU94"
      },
      "source": [
        "## **1.1. Set the Runtime type**\n",
        "---\n",
        "\n",
        "<font size = 4>Go to **Runtime -> Change the Runtime type**\n",
        "\n",
        "<font size = 4>**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n",
        "\n",
        "<font size = 4>**Accelator: GPU** *(Graphics processing unit (GPU)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDhmUgqCStlm",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a0c31d-4ca9-4eaf-eff3-ee1b8f51245f"
      },
      "source": [
        "#Run this cell to check if you have GPU access\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name()=='':\n",
        "  print('You do not have GPU access.') \n",
        "  print('Did you change your runtime ?') \n",
        "  print('If the runtime settings are correct then Google did not allocate GPU to your session')\n",
        "  print('Expect slow performance. To access GPU try reconnecting later')\n",
        "else:\n",
        "  print('You have GPU access')\n",
        "\n",
        "from tensorflow.python.client import device_lib \n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "You have GPU access\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 5575907829891667561\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14401011712\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 14529308404287970412\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqBTeLaImnU"
      },
      "source": [
        "## **1.2. Mount your Google Drive**\n",
        "---\n",
        "<font size = 4> To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n",
        "\n",
        "<font size = 4> Play the cell below to mount your Google Drive and follow the link. In the new browser window, select your drive and select 'Allow', copy the code, paste into the cell and press enter. This will give Colab access to the data on the drive. \n",
        "\n",
        "<font size = 4> Once this is done, your data are available in the **Files** tab on the top left of notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01Djr8v-5pPk",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a5055b-0bfd-4539-9730-a0522fb06388"
      },
      "source": [
        "# mount user's Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TkQcROufgwL"
      },
      "source": [
        "## **1.3. Install PSSR and dependencies**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install fastai==1.0.61\n",
        "!pip install czifile\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "eTZ34b-LL4Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS7lCdiQf_0T"
      },
      "source": [
        "## **1.4. Specify your working folder - need your input**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmx810jDXTbc"
      },
      "source": [
        "root_path = \"/content/gdrive/MyDrive/PSSR-32bit\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMetHM56gMkf"
      },
      "source": [
        "# **2. PSSR - Get to know your training data**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vETWgkZ5v4dm"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1, root_path)\n",
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from fastcore.script import *\n",
        "from utils import *\n",
        "from pathlib import Path\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from time import sleep\n",
        "import shutil\n",
        "import PIL\n",
        "import czifile\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 99999999999999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCG3IlyEjzBa"
      },
      "source": [
        "## **2.1. Specify your datasource - need your input**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNZ7jTg7E5XK"
      },
      "source": [
        "sources = [root_path + '/32bitTS'] #must be in form of array\n",
        "output_file = 'mod_test.csv'\n",
        "only = 'mod_test'\n",
        "skip = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmTld6FTyqbE"
      },
      "source": [
        "src_dirs = []\n",
        "for src in sources:\n",
        "    sub_fldrs = subfolders(Path(src))\n",
        "    if skip: src_dirs += [fldr for fldr in sub_fldrs if fldr.stem not in skip]\n",
        "    elif only: src_dirs += [fldr for fldr in sub_fldrs if fldr.stem in only]\n",
        "    else: src_dirs += sub_fldrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title process_czi()\n",
        "def process_czi(item, category, mode):\n",
        "#This function only takes the first channel of the czi files\n",
        "#since those are the only mitotracker channels\n",
        "    tif_srcs = []\n",
        "    base_name = item.stem\n",
        "    with czifile.CziFile(item) as czi_f:\n",
        "        data = czi_f.asarray()\n",
        "        axes, shape = get_czi_shape_info(czi_f)\n",
        "        channels = shape['C']\n",
        "        depths = shape['Z']\n",
        "        times = shape['T']\n",
        "        #times = min(times, 30) #ONLY USE FIRST 30 frames\n",
        "        x,y = shape['X'], shape['Y']\n",
        "\n",
        "        mid_depth = depths // 2\n",
        "        depth_range = range(max(0,mid_depth-2), min(depths, mid_depth+2))\n",
        "        is_multi = (times > 1) or (depths > 1)\n",
        "\n",
        "        data = czi_f.asarray()\n",
        "        all_rmax = data.max()\n",
        "        all_mi, all_ma = np.percentile(data, [2,99.99])\n",
        "\n",
        "        dtype = data.dtype\n",
        "        #for channel in range(channels): #if other channels are needed, use this line\n",
        "        for channel in range(0,1):\n",
        "            for z in depth_range:\n",
        "                for t in range(times):\n",
        "                    idx = build_index(\n",
        "                        axes, {\n",
        "                            'T': t,\n",
        "                            'C': channel,\n",
        "                            'Z': z,\n",
        "                            'X': slice(0, x),\n",
        "                            'Y': slice(0, y)\n",
        "                        })\n",
        "                    img = data[idx]\n",
        "                    mi, ma = np.percentile(img, [2,99.99])\n",
        "                    if dtype == np.uint8: rmax = 255.\n",
        "                    else: rmax = img.max()\n",
        "                    tif_srcs.append({'fn': item, 'ftype': 'czi', 'multi':int(is_multi), 'category': category, 'dsplit': mode,\n",
        "                                     'uint8': dtype == np.uint8, 'mi': mi, 'ma': ma, 'rmax': rmax,\n",
        "                                     'all_rmax': all_rmax, 'all_mi': all_mi, 'all_ma': all_ma,\n",
        "                                     'mean': img.mean(), 'sd': img.std(),\n",
        "                                     'nc': channels, 'nz': depths, 'nt': times,\n",
        "                                     'z': z, 't': t, 'c':channel, 'x': x, 'y': y})\n",
        "    return tif_srcs"
      ],
      "metadata": {
        "cellView": "form",
        "id": "x094J7X2zIlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szuxHh1XFnQs"
      },
      "source": [
        "def is_live(item):\n",
        "    return item.parent.parts[-3] == 'live'\n",
        "\n",
        "def process_tif(item, category, mode):\n",
        "    tif_srcs = []\n",
        "    img = PIL.Image.open(item)\n",
        "    n_frames = img.n_frames\n",
        "    x,y = img.size\n",
        "    is_multi = n_frames > 1\n",
        "    #n_frames = min(n_frames, 30) #ONLY USE FIRST 30 frames\n",
        "\n",
        "    data = []\n",
        "    for n in range(n_frames):\n",
        "        img.seek(n)\n",
        "        img.load()\n",
        "        img_data = np.array(img)\n",
        "        data.append(img_data)\n",
        "\n",
        "    data = np.stack(data)\n",
        "    all_rmax = data.max()\n",
        "    all_mi, all_ma = np.percentile(data, [2,99.99])\n",
        "\n",
        "    for n in range(n_frames):\n",
        "        img_data = data[n]\n",
        "        dtype = img_data.dtype\n",
        "        mi, ma = np.percentile(img_data, [2,99.99])\n",
        "        if dtype == np.uint8: rmax = 255.\n",
        "        else: rmax = img_data.max()\n",
        "        if is_live(item):\n",
        "            t, z = n, 0\n",
        "            nt, nz = n_frames, 1\n",
        "        else:\n",
        "            t, z = 0, n\n",
        "            nt, nz = 1, n_frames\n",
        "        \n",
        "        print(item)\n",
        "\n",
        "        tif_srcs.append({'fn': item, 'ftype': 'tif', 'multi':int(is_multi), 'category': category, 'dsplit': mode,\n",
        "                         'uint8': dtype==np.uint8, 'mi': mi, 'ma': ma, 'rmax': rmax,\n",
        "                         'all_rmax': all_rmax, 'all_mi': all_mi, 'all_ma': all_ma,\n",
        "                         'mean': img_data.mean(), 'sd': img_data.std(),\n",
        "                         'nc': 1, 'nz': nz, 'nt': nt,\n",
        "                         'z': z, 't': t, 'c':0, 'x': x, 'y': y})\n",
        "    return tif_srcs\n",
        "\n",
        "def process_unk(item, category, mode):\n",
        "    print(f\"**** Unknown: {item}\")\n",
        "    return []\n",
        "\n",
        "def process_item(item, category, mode):\n",
        "    try:\n",
        "        if mode == 'test': return []\n",
        "        else:\n",
        "            item_map = {\n",
        "                '.tif': process_tif,\n",
        "                '.tiff': process_tif,\n",
        "                '.czi': process_czi,\n",
        "            }\n",
        "            map_f = item_map.get(item.suffix, process_unk)\n",
        "            return map_f(item, category, mode)\n",
        "    except Exception as ex:\n",
        "        print(f'err procesing: {item}')\n",
        "        print(ex)\n",
        "        return []\n",
        "\n",
        "def build_tifs(src, mbar=None):\n",
        "    tif_srcs = []\n",
        "    for mode in ['train', 'valid', 'test']:\n",
        "        live = src.parent.parts[-1] == 'live'\n",
        "        src_dir = src / mode\n",
        "        category = src.stem\n",
        "        items = list(src_dir.iterdir()) if src_dir.exists() else []\n",
        "        if items:\n",
        "            for p in progress_bar(items, parent=mbar):\n",
        "                mbar.child.comment = mode\n",
        "                tif_srcs += process_item(p, category=category, mode=mode)\n",
        "    return tif_srcs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7w1fzWrO5-v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ddf9c561-6ec6-4e99-f333-b2caa8c2410d"
      },
      "source": [
        "#pull metadata from datasources\n",
        "mbar = master_bar(src_dirs)\n",
        "tif_srcs = []\n",
        "for src in mbar:\n",
        "    mbar.write(f'process {src.stem}')\n",
        "    tif_srcs += build_tifs(src, mbar=mbar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "process mod_test"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "process mod_test\n",
            "/content/gdrive/MyDrive/PSSR-32bit/32bitTS/mod_test/train/TS0006.tif\n",
            "/content/gdrive/MyDrive/PSSR-32bit/32bitTS/mod_test/valid/TS0014.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UXIgrDn8bC6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ea24c78-59da-4e36-d79a-1f72a4cfe7c7"
      },
      "source": [
        "#save csv to disk\n",
        "tif_src_df = pd.DataFrame(tif_srcs)\n",
        "tif_src_df[['category','dsplit','multi','ftype','uint8','mean','sd','all_rmax','all_mi','all_ma','mi','ma','rmax','nc','nz','nt','c','z','t','x','y','fn']].to_csv(output_file, header=True, index=False)\n",
        "shutil.move(output_file, f'{root_path}/{output_file}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/PSSR-32bit/mod_test.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}