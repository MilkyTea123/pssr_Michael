{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9zNGvape2-I"
   },
   "source": [
    "# **Point Scanning Super Resolution (PSSR) - Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4-r1gE7Iamv"
   },
   "source": [
    "# **Preparation**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastai==1.0.61\n",
    "!pip install czifile\n",
    "!pip install imageio==2.8.0\n",
    "!pip install tifffile==2020.5.5\n",
    "!pip install scikit-image==0.19.3\n",
    "\n",
    "from IPython.display import clear_output \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/51/2c0959c5adf988c44d9e1e0d940f5b074516ecc87e96b1af25f59de9ba38/pip-23.0.1-py3-none-any.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-23.0.1\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: setuptools in /snap/jupyter/6/lib/python3.7/site-packages (41.0.1)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-67.6.0-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: setuptools\n",
      "Successfully installed setuptools-67.6.0\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /snap/jupyter/6/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/gigo/snap/jupyter/common/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: setuptools in /home/gigo/snap/jupyter/common/lib/python3.7/site-packages (from tensorflow) (67.6.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-23.0-py3-none-any.whl (42 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /snap/jupyter/6/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.33.4)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.3-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.5/177.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-6.1.0-py3-none-any.whl (21 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (171 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.0/171.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /snap/jupyter/6/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2019.3.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, zipp, wrapt, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, packaging, opt-einsum, oauthlib, MarkupSafe, keras, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, cachetools, astunparse, absl-py, werkzeug, requests, importlib-metadata, google-auth, requests-oauthlib, markdown, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 charset-normalizer-3.1.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.16.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 h5py-3.8.0 idna-3.4 importlib-metadata-6.1.0 keras-2.11.0 libclang-16.0.0 markdown-3.4.3 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-23.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0 typing-extensions-4.5.0 urllib3-1.26.15 werkzeug-2.2.3 wrapt-1.15.0 zipp-3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade setuptools\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting fastcore\n",
      "  Downloading fastcore-1.5.28-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pip in /home/gigo/snap/jupyter/common/lib/python3.7/site-packages (from fastcore) (23.0.1)\n",
      "Requirement already satisfied: packaging in /home/gigo/snap/jupyter/common/lib/python3.7/site-packages (from fastcore) (23.0)\n",
      "Installing collected packages: fastcore\n",
      "Successfully installed fastcore-1.5.28\n"
     ]
    }
   ],
   "source": [
    "!pip install fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting markupsafe==2.0.1\n",
      "  Downloading MarkupSafe-2.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (31 kB)\n",
      "Installing collected packages: markupsafe\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 2.1.2\n",
      "    Uninstalling MarkupSafe-2.1.2:\n",
      "      Successfully uninstalled MarkupSafe-2.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "werkzeug 2.2.3 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed markupsafe-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install markupsafe==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5_nSag2fU94"
   },
   "source": [
    "## **Set the Runtime Type**\n",
    "---\n",
    "\n",
    "<font size = 4>Go to **Runtime -> Change the Runtime type**\n",
    "\n",
    "<font size = 4>**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n",
    "\n",
    "<font size = 4>**Accelator: GPU** *(Graphics processing unit (GPU)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDhmUgqCStlm",
    "outputId": "423c7ca6-686c-4a70-8a38-239bccf3bcca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You do not have GPU access.\n",
      "Did you change your runtime ?\n",
      "If the runtime settings are correct then Google did not allocate GPU to your session\n",
      "Expect slow performance. To access GPU try reconnecting later\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2751475432181633242\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this cell to check if you have GPU access\n",
    "\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name()=='':\n",
    "  print('You do not have GPU access.') \n",
    "  print('Did you change your runtime ?') \n",
    "  print('If the runtime settings are correct then Google did not allocate GPU to your session')\n",
    "  print('Expect slow performance. To access GPU try reconnecting later')\n",
    "else:\n",
    "  print('You have GPU access')\n",
    "\n",
    "from tensorflow.python.client import device_lib \n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS7lCdiQf_0T"
   },
   "source": [
    "\\## **Specify Your Working Folder - need your input**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Vmx810jDXTbc"
   },
   "outputs": [],
   "source": [
    "root_path = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TkQcROufgwL"
   },
   "source": [
    "## **Install PSSR and Dependencies**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vETWgkZ5v4dm",
    "outputId": "5cd9632b-1ad4-4bf7-c1e1-661620fe762d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, root_path)\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastcore.script import *\n",
    "from utils import *\n",
    "from pathlib import Path\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from time import sleep\n",
    "import shutil\n",
    "import PIL\n",
    "import czifile\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 99999999999999\n",
    "\n",
    "import PIL.Image\n",
    "import imageio\n",
    "\n",
    "from fastai.callbacks import *\n",
    "from fastai.distributed import *\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "from fastai.vision.models import resnet18, resnet34, resnet50\n",
    "from skimage.util import random_noise\n",
    "from skimage import filters\n",
    "from utils.resnet import *\n",
    "from utils.utils import unet_image_from_tiles_blend\n",
    "\n",
    "from utils.crappifiers import *\n",
    "import torchvision\n",
    "import glob\n",
    "from PIL import Image\n",
    "from skimage.transform import rescale\n",
    "from scipy.ndimage.interpolation import zoom as npzoom\n",
    "\n",
    "from pandas.core.arrays.interval import NA\n",
    "from numpy import NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LQY61nXssJt1"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-08e64c1a0e87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/gigo/snap/jupyter/common/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m_new_torch_cuda_set_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0m_old_torch_cuda_set_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_new_torch_cuda_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0m_old_torch_cuda_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_new_torch_cuda_set_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gigo/snap/jupyter/common/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gigo/snap/jupyter/common/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "if 'learn' in locals():\n",
    "    del learn\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMetHM56gMkf"
   },
   "source": [
    "# **PSSR 01 - Get to Know Your Training Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCG3IlyEjzBa"
   },
   "source": [
    "## **Specify Your Datasource - need your input**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNZ7jTg7E5XK"
   },
   "outputs": [],
   "source": [
    "sources = [root_path + '/HRSet'] #must be in form of array\n",
    "output_file = 'high_res_pssr.csv'∏\n",
    "only = 'sources_modded'\n",
    "skip = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmTld6FTyqbE"
   },
   "outputs": [],
   "source": [
    "src_dirs = []\n",
    "for src in sources:\n",
    "    sub_fldrs = subfolders(Path(src))\n",
    "    if skip: src_dirs += [fldr for fldr in sub_fldrs if fldr.stem not in skip]\n",
    "    elif only: src_dirs += [fldr for fldr in sub_fldrs if fldr.stem in only]\n",
    "    else: src_dirs += sub_fldrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "089Lg4eD7JT0"
   },
   "outputs": [],
   "source": [
    "#@title process_czi()\n",
    "def process_czi(item, category, mode):\n",
    "#This function only takes the first channel of the czi files\n",
    "#since those are the only mitotracker channels\n",
    "    tif_srcs = []\n",
    "    base_name = item.stem\n",
    "    print('czi')\n",
    "    with czifile.CziFile(item) as czi_f:\n",
    "        data = czi_f.asarray()\n",
    "        axes, shape = get_czi_shape_info(czi_f)\n",
    "        channels = shape['C']\n",
    "        depths = shape['Z']\n",
    "        times = shape['T']\n",
    "        #times = min(times, 30) #ONLY USE FIRST 30 frames\n",
    "        x,y = shape['X'], shape['Y']\n",
    "\n",
    "        mid_depth = depths // 2\n",
    "        depth_range = range(max(0,mid_depth-2), min(depths, mid_depth+2))\n",
    "        is_multi = (times > 1) or (depths > 1)\n",
    "\n",
    "        data = czi_f.asarray()\n",
    "        all_rmax = data.max()\n",
    "        all_mi, all_ma = np.percentile(data, [2,99.99])\n",
    "\n",
    "        dtype = data.dtype\n",
    "        #for channel in range(channels): #if other channels are needed, use this line\n",
    "        for channel in range(0,1):\n",
    "            for z in depth_range:\n",
    "                for t in range(times):\n",
    "                    idx = build_index(\n",
    "                        axes, {\n",
    "                            'T': t,\n",
    "                            'C': channel,\n",
    "                            'Z': z,\n",
    "                            'X': slice(0, x),\n",
    "                            'Y': slice(0, y)\n",
    "                        })\n",
    "                    img = data[idx]\n",
    "                    mi, ma = np.percentile(img, [2,99.99])\n",
    "                    if dtype == np.uint8: rmax = 255.\n",
    "                    else: rmax = img.max()\n",
    "                    tif_srcs.append({'fn': item, 'ftype': 'czi', 'multi':int(is_multi), 'category': category, 'dsplit': mode,\n",
    "                                     'uint8': dtype == np.uint8, 'mi': mi, 'ma': ma, 'rmax': rmax,\n",
    "                                     'all_rmax': all_rmax, 'all_mi': all_mi, 'all_ma': all_ma,\n",
    "                                     'mean': img.mean(), 'sd': img.std(),\n",
    "                                     'nc': channels, 'nz': depths, 'nt': times,\n",
    "                                     'z': z, 't': t, 'c':channel, 'x': x, 'y': y})\n",
    "    return tif_srcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szuxHh1XFnQs"
   },
   "outputs": [],
   "source": [
    "def is_live(item):\n",
    "    return item.parent.parts[-3] == 'live'\n",
    "\n",
    "def process_tif(item, category, mode):\n",
    "    mods = {\n",
    "        'original': lambda x: x,\n",
    "        'rot90': np.rot90,\n",
    "        'rot180': lambda x: np.rot90(x, 2),\n",
    "        'rot270': lambda x: np.rot90(x, 3),\n",
    "        'hflip': np.fliplr,\n",
    "        'vflip': np.flip,\n",
    "        'zoom_tl': lambda x: np.repeat(np.repeat(x[:int(x.shape[0]/2), :int(x.shape[1]/2)], 2, 0), 2, 1),\n",
    "        'zoom_tr': lambda x: np.repeat(np.repeat(x[:int(x.shape[0]/2), int(x.shape[1]/2):], 2, 0), 2, 1),\n",
    "        'zoom_bl': lambda x: np.repeat(np.repeat(x[int(x.shape[0]/2):, :int(x.shape[1]/2)], 2, 0), 2, 1),\n",
    "        'zoom_br': lambda x: np.repeat(np.repeat(x[int(x.shape[0]/2):, int(x.shape[1]/2):], 2, 0), 2, 1)\n",
    "    }\n",
    "\n",
    "    tif_srcs = []\n",
    "    img = PIL.Image.open(item)\n",
    "    n_frames = img.n_frames\n",
    "    x,y = img.size\n",
    "    is_multi = n_frames > 1\n",
    "    #n_frames = min(n_frames, 30) #ONLY USE FIRST 30 frames\n",
    "\n",
    "    data = []\n",
    "    for n in range(n_frames):\n",
    "        img.seek(n)\n",
    "        img.load()\n",
    "        img_data = np.array(img)\n",
    "\n",
    "        data.append(img_data)\n",
    "\n",
    "    data = np.stack(data)\n",
    "    all_rmax = data.max().astype(np.float32)\n",
    "    all_rmin = data.min().astype(np.float32)\n",
    "    all_mi, all_ma = np.percentile(data, [2,99.99]).astype(np.float32)\n",
    "\n",
    "    dir = sources[0] + f'/{category}_modded'\n",
    "    if not os.path.isdir(dir):\n",
    "        os.mkdir(dir)\n",
    "    if not os.path.isdir(dir + f'/{mode}'):\n",
    "        print(dir + f'/{mode}')\n",
    "        os.mkdir(dir + f'/{mode}')\n",
    "\n",
    "    for n in range(n_frames):\n",
    "        img_data = data[n]\n",
    "        dtype = img_data.dtype\n",
    "        mi, ma = np.percentile(img_data, [2,99.99]).astype(np.float32)\n",
    "        # if dtype == np.int32: rmax = np.iinfo(np.int32).max\n",
    "        # else: rmax = img_data.max()\n",
    "        rmax = img_data.max().astype(np.float32)\n",
    "        rmin = img_data.min().astype(np.float32)\n",
    "        if is_live(item):\n",
    "            t, z = n, 0\n",
    "            nt, nz = n_frames, 1\n",
    "        else:\n",
    "            t, z = 0, n\n",
    "            nt, nz = 1, n_frames\n",
    "\n",
    "        for mod in mods.keys():\n",
    "            modname = str(item).split('/')[-1].split('.')\n",
    "            modname[0], modname[-1] = modname[0] + f'_{mod}', '.' + modname[-1]\n",
    "            modname = ''.join(modname)\n",
    "            item_mod_name = f'{dir}/{mode}/{modname}'\n",
    "\n",
    "            Image.fromarray(mods[mod](np.array(Image.open(item)))).save(item_mod_name)\n",
    "\n",
    "            tif_srcs.append({'fn': item_mod_name, 'ftype': 'tif', 'multi':int(is_multi), 'category': category, 'dsplit': mode,\n",
    "                            'int32': dtype==np.int32, 'mi': mi, 'ma': ma, 'rmin': rmin, 'rmax': rmax,\n",
    "                            'all_rmin': all_rmin, 'all_rmax': all_rmax, 'all_mi': all_mi, 'all_ma': all_ma,\n",
    "                            'mean': img_data.mean(), 'sd': img_data.std(),\n",
    "                            'nc': 1, 'nz': nz, 'nt': nt,\n",
    "                            'z': z, 't': t, 'c':0, 'x': x, 'y': y})\n",
    "    return tif_srcs\n",
    "\n",
    "def process_unk(item, category, mode):\n",
    "    print(f\"**** Unknown: {item}\")\n",
    "    return []\n",
    "\n",
    "def process_item(item, category, mode):\n",
    "    try:\n",
    "        if mode == 'test': return []\n",
    "        else:\n",
    "            item_map = {\n",
    "                '.tif': process_tif,\n",
    "                '.tiff': process_tif,\n",
    "                '.czi': process_czi,\n",
    "            }\n",
    "            map_f = item_map.get(item.suffix, process_unk)\n",
    "            return map_f(item, category, mode)\n",
    "    except Exception as ex:\n",
    "        print(f'err procesing: {item}')\n",
    "        print(ex)\n",
    "        return []\n",
    "\n",
    "def build_tifs(src, mbar=None):\n",
    "    tif_srcs = []\n",
    "    for mode in ['train', 'valid', 'test']:\n",
    "        live = src.parent.parts[-1] == 'live'\n",
    "        src_dir = src / mode\n",
    "        category = src.stem\n",
    "        items = list(src_dir.iterdir()) if src_dir.exists() else []\n",
    "        if items:\n",
    "            for p in progress_bar(items, parent=mbar):\n",
    "                mbar.child.comment = mode\n",
    "                tif_srcs += process_item(p, category=category, mode=mode)\n",
    "    return tif_srcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "o7w1fzWrO5-v",
    "outputId": "77f4cab7-d126-4c59-91a1-cbe59b875e6b"
   },
   "outputs": [],
   "source": [
    "#pull metadata from datasources\n",
    "mbar = master_bar(src_dirs)\n",
    "tif_srcs = []\n",
    "for src in mbar:\n",
    "    mbar.write(f'process {src.stem}')\n",
    "    tif_srcs += build_tifs(src, mbar=mbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3UXIgrDn8bC6",
    "outputId": "39eca72d-6f0d-49c4-b22f-fd59df34f196"
   },
   "outputs": [],
   "source": [
    "#save csv to disk\n",
    "tif_src_df = pd.DataFrame(tif_srcs)\n",
    "tif_src_df[['category','dsplit','multi','ftype','int32','mean','sd','all_rmin','all_rmax','all_mi','all_ma','mi','ma','rmin','rmax','nc','nz','nt','c','z','t','x','y','fn']].to_csv(output_file, header=True, index=False)\n",
    "shutil.move(output_file, f'{root_path}/{output_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjDTzO01qx4k"
   },
   "source": [
    "# **PSSR 02 - Generate Training Datasets**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiiSdolYrmQZ"
   },
   "outputs": [],
   "source": [
    "from pandas._libs.lib import tuples_to_object_array\n",
    "def need_cache_flush(tile_stats, last_stats):\n",
    "    if last_stats is None: return True\n",
    "    if tile_stats['fn'] != last_stats['fn']: return True\n",
    "    return False\n",
    "\n",
    "def get_tile_puller(tile_stat, crap_func, t_frames, z_frames):\n",
    "    fn = tile_stat['fn']\n",
    "    ftype = tile_stat['ftype']\n",
    "    nz = tile_stat['nz']\n",
    "    nt = tile_stat['nt']\n",
    "\n",
    "    half_z = z_frames // 2\n",
    "    half_t = t_frames // 2\n",
    "\n",
    "    if ftype == 'czi':\n",
    "        img_f = czifile.CziFile(fn)\n",
    "        proc_axes, proc_shape = get_czi_shape_info(img_f)\n",
    "        img_data = img_f.asarray()\n",
    "        img_data = img_data.astype(np.float32)\n",
    "\n",
    "        def czi_get(istat):\n",
    "            c,z,t,x,y,mi,ma,is_uint8,rmax,all_rmax,all_ma = [istat[fld] for fld in ['c','z','t','x','y','mi','ma','uint8','rmax','all_rmax','all_ma']]\n",
    "            if is_uint8:\n",
    "                mi, ma, rmax = 0., 255.0, 255.0\n",
    "                all_ma, all_rmax = 255.0, 255.0\n",
    "\n",
    "            t_slice = slice(t-half_t, t+half_t+1) if half_t > 0 else t\n",
    "            z_slice = slice(z-half_z, z+half_z+1) if half_z > 0 else z\n",
    "            idx = build_index(\n",
    "                proc_axes, {\n",
    "                    'C': c,\n",
    "                    'T': t_slice,\n",
    "                    'Z': z_slice,\n",
    "                    'X': slice(0, x),\n",
    "                    'Y': slice(0, y)\n",
    "                })\n",
    "            img = img_data[idx].copy()\n",
    "            img /= all_rmax\n",
    "            if len(img.shape) <= 2: img = img[None]\n",
    "            return img\n",
    "\n",
    "        img_get = czi_get\n",
    "        img_get._to_close = img_f\n",
    "    else:\n",
    "        pil_img = PIL.Image.open(fn)\n",
    "        def pil_get(istat):\n",
    "            c,z,t,x,y,mi,ma,is_int32,rmax,all_rmax,all_ma = [istat[fld] for fld in ['c','z','t','x','y','mi','ma','int32','rmax','all_rmax','all_ma']]\n",
    "            if half_t > 0: n_start, n_end = t-half_t, t+half_t+1\n",
    "            elif half_z > 0: n_start, n_end = z-half_z, z+half_z+1\n",
    "            else: n_start, n_end = 0,1\n",
    "\n",
    "            # if is_int32:\n",
    "            #     low, high = np.finfo(np.float32).min, np.finfo(np.float32).max\n",
    "            #     mi, ma, rmax = low, high, high\n",
    "            #     all_ma, all_rmax = high, high\n",
    "\n",
    "            img_array = []\n",
    "            img_max = 0\n",
    "            for ix in range(n_start, n_end):\n",
    "                pil_img.seek(ix)\n",
    "                pil_img.load()\n",
    "                img = np.array(pil_img).astype(np.float32)\n",
    "\n",
    "                # img_min, img_max = img.min(), img.max\n",
    "                # img = (((img + 212.) / 2259.) * np.iinfo(np.uint8).max).astype(np.uint8)\n",
    "\n",
    "                if len(img.shape) > 2: img = img[:,:,0]\n",
    "                img_array.append(img.copy())\n",
    "                \n",
    "                img_max = max(img_max, img.max())\n",
    "\n",
    "            img = np.stack(img_array)\n",
    "            img = img\n",
    "            img /= img_max\n",
    "\n",
    "            return img\n",
    "\n",
    "        img_get = pil_get\n",
    "        img_get._to_close = pil_img\n",
    "\n",
    "\n",
    "    def puller(istat, tile_folder, crap_folder, close_me=False):\n",
    "        if close_me:\n",
    "            img_get._to_close.close()\n",
    "            return None\n",
    "\n",
    "        id = istat['index']\n",
    "        fn = Path(istat['fn'])\n",
    "        tile_sz = istat['tile_sz']\n",
    "        c,z,t,x,y,mi,ma,is_int32,rmin,rmax,mean = [istat[fld] for fld in ['c','z','t','x','y','mi','ma','int32','rmin','rmax','mean']]\n",
    "\n",
    "        raw_data = img_get(istat)\n",
    "        img_data = (raw_data * rmax).astype(np.float32)\n",
    "\n",
    "        thresh = np.percentile(img_data, 2)\n",
    "        thresh_pct = (img_data > thresh).mean() * 0.30\n",
    "\n",
    "        frame_count = img_data.shape[0]\n",
    "        mid_frame = frame_count // 2\n",
    "        crop_img, box = draw_random_tile(img_data[mid_frame], istat['tile_sz'], thresh, thresh_pct)\n",
    "        crop_img.save(tile_folder/f'{id:06d}_{fn.stem}.tif')\n",
    "        \n",
    "        if crap_func and crap_folder:\n",
    "            if frame_count > 1:\n",
    "                crap_data = []\n",
    "                for i in range(frame_count):\n",
    "                    frame_img = img_data[i, box[0]:box[2], box[1]:box[3]]\n",
    "                    crap_frame = crap_func(frame_img)\n",
    "                    crap_data.append(np.array(crap_frame))\n",
    "                multi_array = np.stack(crap_data)\n",
    "                np.save(crap_folder/f'{id:06d}_{fn.stem}.npy', multi_array)\n",
    "            else:\n",
    "                crap_img = crap_func(crop_img)\n",
    "                crap_img.save(crap_folder/f'{id:06d}_{fn.stem}.tif')\n",
    "\n",
    "        info = dict(istat)\n",
    "        info['id'] = id\n",
    "        info['box'] = box\n",
    "        info['tile_sz'] = tile_sz\n",
    "        crop_data = np.array(crop_img)\n",
    "        info['after_mean'] = crop_data.mean()\n",
    "        info['after_sd'] = crop_data.std()\n",
    "        info['after_max'] = crop_data.max()\n",
    "        info['after_min'] = crop_data.min()\n",
    "        return info\n",
    "\n",
    "    return puller\n",
    "\n",
    "def check_info(info, t_frames, z_frames):\n",
    "    t_space = t_frames // 2\n",
    "    z_space = z_frames // 2\n",
    "\n",
    "    z_ok = (info['nz'] >= z_frames) and (info['z'] >= z_space) and (info['z'] < (info['nz']-z_space))\n",
    "    t_ok = (info['nt'] >= t_frames) and (info['t'] >= t_space) and (info['t'] < (info['nt']-t_space))\n",
    "\n",
    "    return t_ok and z_ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvHGTP00rqqK"
   },
   "source": [
    "## **Specify Your Datasource - need your input**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5YVTH8Ortuk"
   },
   "outputs": [],
   "source": [
    "out = Path(root_path) #dataset folder, Path\n",
    "info = Path(root_path + '/high_res_pssr.csv') #path of the metadata csv file, Path\n",
    "tile = 128 #generated training tile size, int\n",
    "n_train: int = 2500 #number of train tiles, int\n",
    "n_valid: int = 270 #number of validation tiles', int\n",
    "crap_func = 'new_crap_AG_SP' #crappifier name, str, check utils/crappifiers.py for more details\n",
    "n_frames = 1 #number of frames, int, 1 if singleframe, >1 if multiframe, 5 for multiframe by default\n",
    "lr_type = 's' # (s)ingle, (t) multi or (z) multi', string, if multiframe, t if XYT time-lapse, z if XYZ 3D stack\n",
    "scale = 4 # upsample factor, int\n",
    "upsample = False # if LR-Bilinear is needed to save to disk, boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJmJ_YhqrxNm"
   },
   "outputs": [],
   "source": [
    "up = 'up' if upsample else ''\n",
    "if lr_type not in ['s','t','z']:\n",
    "    print('lr_type should be s, t or z')\n",
    "    # return 1\n",
    "\n",
    "if lr_type == 's':\n",
    "    z_frames, t_frames = 1, 1\n",
    "elif lr_type == 't':\n",
    "    z_frames, t_frames = 1, n_frames\n",
    "elif lr_type == 'z':\n",
    "    z_frames, t_frames = n_frames, 1\n",
    "\n",
    "out = ensure_folder(out/f'{lr_type}_{n_frames}_{info.stem}_{crap_func}')\n",
    "if out.exists(): shutil.rmtree(out)\n",
    "out.mkdir(parents=True, mode=0o775, exist_ok=True)\n",
    "\n",
    "crap_func = eval(crap_func)\n",
    "if not crap_func is None:\n",
    "    if not callable(crap_func):\n",
    "        print('crap_func is not callable')\n",
    "        crap_func = None\n",
    "    else:\n",
    "        crap_func = partial(crap_func, scale=scale, upsample=upsample)\n",
    "\n",
    "info = pd.read_csv(info)\n",
    "info = info.loc[info.nz >= z_frames]\n",
    "info = info.loc[info.nt >= t_frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tR1Ig1iKrzAl",
    "outputId": "3f05c196-fd75-43b8-9a59-546aa58456fd"
   },
   "outputs": [],
   "source": [
    "tile_infos = []\n",
    "for mode, n_samples in [('train', n_train),('valid', n_valid)]:\n",
    "    mode_info = info.loc[info.dsplit == mode]\n",
    "    categories = list(mode_info.groupby('category'))\n",
    "    files_by_category  = {c:list(info.groupby('fn')) for c,info in categories}\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        category, cat_df = random.choice(categories)\n",
    "        fn, item_df = random.choice(files_by_category[category])\n",
    "        legal_choices = [item_info for ix, item_info in item_df.iterrows() if check_info(item_info, t_frames, z_frames)]\n",
    "\n",
    "        assert(legal_choices)\n",
    "        item_info = random.choice(legal_choices)\n",
    "        for tile_sz in [tile]:\n",
    "            item_d = dict(item_info)\n",
    "            item_d['tile_sz'] = tile_sz\n",
    "            tile_infos.append(item_d)\n",
    "\n",
    "tile_info_df = pd.DataFrame(tile_infos).reset_index()\n",
    "print('num tile pulls:', len(tile_infos))\n",
    "print(tile_info_df.groupby('category').fn.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEpFaGkWr1pD",
    "outputId": "15d5ad63-6b25-4e3a-e138-104add2d9a63"
   },
   "outputs": [],
   "source": [
    "last_stat = None\n",
    "tile_pull_info = []\n",
    "tile_puller = None\n",
    "\n",
    "multi_str = f'_{lr_type}_{n_frames}' if lr_type != 's' else ''\n",
    "mbar = master_bar(tile_info_df.groupby('fn'))\n",
    "for fn, tile_stats in mbar:\n",
    "    for i, tile_stat in progress_bar(list(tile_stats.iterrows()), parent=mbar):\n",
    "        try:\n",
    "            mode = tile_stat['dsplit']\n",
    "            category = tile_stat['category']\n",
    "            tile_sz = tile_stat['tile_sz']\n",
    "            tile_folder = ensure_folder(out / f'hr_t_{tile_sz}{multi_str}' / mode / category)\n",
    "            if crap_func:\n",
    "                crap_folder = ensure_folder(out / f'lr{up}_t_{tile_sz}{multi_str}' / mode / category)\n",
    "            else: crap_folder = None\n",
    "\n",
    "            if need_cache_flush(tile_stat, last_stat):\n",
    "                if tile_puller:\n",
    "                    tile_puller(None, None, None, close_me=True)\n",
    "                last_stat = tile_stat.copy()\n",
    "                tile_sz = tile_stat['tile_sz']\n",
    "                tile_puller = get_tile_puller(tile_stat, crap_func, t_frames, z_frames)\n",
    "            tile_pull_info.append(tile_puller(tile_stat, tile_folder, crap_folder))\n",
    "        except MemoryError as error:\n",
    "            # some files are too big to read\n",
    "            fn = Path(tile_stat['fn'])\n",
    "            print(f'too big: {fn.stem}')\n",
    "\n",
    "pd.DataFrame(tile_pull_info).to_csv(out/f'tiles{multi_str}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxRDXI5kr6O-"
   },
   "source": [
    "# **PSSR 03 - Train Your Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_5rWFD1sNtQ"
   },
   "source": [
    "## **Hyper-Parameter Configuration - need your input**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "afaoK0ASr5z8"
   },
   "outputs": [],
   "source": [
    "#basic adjustable hyper-parameters - configure as needed\n",
    "datasetname = 's_1_high_res_pssr_new_crap_AG_SP'\n",
    "tile_sz = 128\n",
    "n_frames = 1\n",
    "lr_type = 's' #'s' or 't' or 'z'\n",
    "bs = 6\n",
    "size = 512\n",
    "# lr = 4e-4\n",
    "lr = 8e-4\n",
    "cycles = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "izJuXDCssVdq"
   },
   "outputs": [],
   "source": [
    "#advanced adjustable hyper-parameters - keep default numbers in most cases\n",
    "\n",
    "#data augmentation related\n",
    "cutout = False\n",
    "norm = True\n",
    "# mode = 'L'\n",
    "mode = 'I'\n",
    "\n",
    "#network architecture\n",
    "arch = 'wnresnet34'\n",
    "attn = True\n",
    "blur = True\n",
    "final_blur = True\n",
    "bottle = True\n",
    "last_cross = True\n",
    "\n",
    "#fitting related\n",
    "l1_loss = False\n",
    "lr_start = None\n",
    "# load_name = None\n",
    "load_name = \"scale4_tile128_size512_epoch75_lr5e-4_best_512\"\n",
    "freeze = False\n",
    "wd = 1e-3\n",
    "save_name = 'scale4_tile128_size512_epoch100_lr8e-4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKjeQoE_sY1r"
   },
   "source": [
    "## **Prepare Databunch**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "s5cMdQw4saH6"
   },
   "outputs": [],
   "source": [
    "def get_src(x_data, y_data, n_frames=1, mode='L'):\n",
    "    def map_to_hr(x):\n",
    "        return y_data/x.relative_to(x_data).with_suffix('.tif')\n",
    "\n",
    "    if n_frames == 1:\n",
    "        src = (ImageImageList\n",
    "                .from_folder(x_data, convert_mode=mode)\n",
    "                .split_by_folder()\n",
    "                .label_from_func(map_to_hr, convert_mode=mode))\n",
    "    else:\n",
    "        src = (MultiImageImageList\n",
    "                .from_folder(x_data, extensions=['.npy'])\n",
    "                .split_by_folder()\n",
    "                .label_from_func(map_to_hr, convert_mode=mode))\n",
    "    return src\n",
    "\n",
    "def get_data(bs, size, x_data, y_data,\n",
    "             n_frames=1,\n",
    "             max_rotate=10.,\n",
    "             min_zoom=1., max_zoom=1.1,\n",
    "             use_cutout=False,\n",
    "             use_noise=False,\n",
    "             scale=4,\n",
    "             xtra_tfms=None,\n",
    "             gauss_sigma=(0.4,0.7),\n",
    "             pscale=(5,30),\n",
    "             mode='L',\n",
    "             norm=False,\n",
    "             **kwargs):\n",
    "    src = get_src(x_data, y_data, n_frames=n_frames, mode=mode)\n",
    "\n",
    "    x_tfms, y_tfms = get_xy_transforms(\n",
    "                          max_rotate=max_rotate,\n",
    "                          min_zoom=min_zoom, max_zoom=max_zoom,\n",
    "                          use_cutout=use_cutout,\n",
    "                          use_noise=use_noise,\n",
    "                          gauss_sigma=gauss_sigma,\n",
    "                          pscale=pscale,\n",
    "                          xtra_tfms = xtra_tfms)\n",
    "    x_size = size // scale\n",
    "    data = (src\n",
    "            .transform(x_tfms, size=x_size)\n",
    "            .transform_y(y_tfms, size=size)\n",
    "            .databunch(bs=bs, **kwargs))\n",
    "    if norm:\n",
    "        print('normalizing x and y data')\n",
    "        data = data.normalize(do_y=True)\n",
    "    #data.c = 3 #why?\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVoQ4o9xsh6h",
    "outputId": "69490906-c5da-4967-80f7-9886e2f8bd0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing x and y data\n",
      "bs: 6 size:  512\n"
     ]
    }
   ],
   "source": [
    "datasets = Path(root_path)\n",
    "dataset = datasets/datasetname\n",
    "if tile_sz is None:\n",
    "    hr_tifs = dataset/f'hr'\n",
    "    lr_tifs = dataset/f'lr'\n",
    "else:\n",
    "    multi_str = f'_{lr_type}_{n_frames}' if lr_type != 's' else ''\n",
    "    hr_tifs = dataset/f'hr_t_{tile_sz:d}{multi_str}'\n",
    "    lr_tifs = dataset/f'lr_t_{tile_sz:d}{multi_str}'\n",
    "\n",
    "data = get_data(bs, size, lr_tifs, hr_tifs, n_frames=n_frames, max_zoom=4.,\n",
    "                use_cutout=cutout, mode=mode, norm=norm)\n",
    "print('bs:', bs, 'size: ', size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfgjxgIHsim_"
   },
   "source": [
    "## **Set Up Learner**\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A67K0Ne6sltO",
    "outputId": "0aa4ecfa-5868-42d7-dc54-3470456c882d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  <function mse_loss at 0x7f3e184fe9e0>\n",
      "loaded scale4_tile128_size512_epoch75_lr5e-4_best_512\n"
     ]
    }
   ],
   "source": [
    "# Set up the learner\n",
    "if save_name is None: \n",
    "    save_name = f'{datasetname}_{cycles}epochs'\n",
    "pickle_models = Path(root_path)/'stats/models'\n",
    "pth_models = Path(root_path)/'models'\n",
    "if l1_loss: loss = F.l1_loss\n",
    "else: loss = F.mse_loss\n",
    "print('loss: ', loss)\n",
    "\n",
    "callback_fns = []\n",
    "callback_fns.append(partial(SaveModelCallback, name=f'{save_name}_best_{size}'))\n",
    "\n",
    "wnres_args = {\n",
    "    'blur': blur,\n",
    "    'blur_final': final_blur,\n",
    "    'bottle': bottle,\n",
    "    'self_attention': attn,\n",
    "    'last_cross': True\n",
    "}\n",
    "arch = eval(arch)\n",
    "learn = wnres_unet_learner(data, arch, in_c=n_frames, wnres_args=wnres_args,\n",
    "                          path=Path('.'), loss_func=loss, metrics=sr_metrics,\n",
    "                          model_dir=pth_models, callback_fns=callback_fns, wd=wd)\n",
    "\n",
    "if load_name:\n",
    "    learn = learn.load(f'{load_name}')\n",
    "    print(f'loaded {load_name}')\n",
    "\n",
    "if freeze: learn.freeze()\n",
    "\n",
    "if not lr_start is None: lr = slice(lr_start, lr)\n",
    "else: lr = slice(None, lr, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XRWPTO5sqOy"
   },
   "source": [
    "## **Training**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copied scale4_tile128_size512_epoch75_lr5e-4_best_512 to scale4_tile128_size512_epoch100_lr8e-4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "iLjiOeZSspl0",
    "outputId": "4495a888-3a61-41da-cdf1-c320b6b84997"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gigo/pssr_Michael/PSSR_All_32bit.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gigo/pssr_Michael/PSSR_All_32bit.ipynb#X46sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mint\u001b[39m(cycles \u001b[39m/\u001b[39m \u001b[39m5\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gigo/pssr_Michael/PSSR_All_32bit.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gigo/pssr_Michael/PSSR_All_32bit.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     learn\u001b[39m.\u001b[39;49mfit_one_cycle(\u001b[39mint\u001b[39;49m(cycles \u001b[39m/\u001b[39;49m \u001b[39m5\u001b[39;49m), lr)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gigo/pssr_Michael/PSSR_All_32bit.ipynb#X46sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     learn\u001b[39m.\u001b[39msave(save_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gigo/pssr_Michael/PSSR_All_32bit.ipynb#X46sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msave #\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pssrMichael/lib/python3.10/site-packages/fastai/train.py:23\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m callbacks \u001b[39m=\u001b[39m listify(callbacks)\n\u001b[1;32m     21\u001b[0m callbacks\u001b[39m.\u001b[39mappend(OneCycleScheduler(learn, max_lr, moms\u001b[39m=\u001b[39mmoms, div_factor\u001b[39m=\u001b[39mdiv_factor, pct_start\u001b[39m=\u001b[39mpct_start,\n\u001b[1;32m     22\u001b[0m                                    final_div\u001b[39m=\u001b[39mfinal_div, tot_epochs\u001b[39m=\u001b[39mtot_epochs, start_epoch\u001b[39m=\u001b[39mstart_epoch))\n\u001b[0;32m---> 23\u001b[0m learn\u001b[39m.\u001b[39;49mfit(cyc_len, max_lr, wd\u001b[39m=\u001b[39;49mwd, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[0;32m~/anaconda3/envs/pssrMichael/lib/python3.10/site-packages/fastai/basic_train.py:200\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mlr,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mwd \u001b[39m=\u001b[39m lr,wd\n\u001b[1;32m    199\u001b[0m callbacks \u001b[39m=\u001b[39m [cb(\u001b[39mself\u001b[39m) \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_fns \u001b[39m+\u001b[39m listify(defaults\u001b[39m.\u001b[39mextra_callback_fns)] \u001b[39m+\u001b[39m listify(callbacks)\n\u001b[0;32m--> 200\u001b[0m fit(epochs, \u001b[39mself\u001b[39;49m, metrics\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetrics, callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks\u001b[39m+\u001b[39;49mcallbacks)\n",
      "File \u001b[0;32m~/anaconda3/envs/pssrMichael/lib/python3.10/site-packages/fastai/basic_train.py:101\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m xb,yb \u001b[39min\u001b[39;00m progress_bar(learn\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtrain_dl, parent\u001b[39m=\u001b[39mpbar):\n\u001b[1;32m    100\u001b[0m     xb, yb \u001b[39m=\u001b[39m cb_handler\u001b[39m.\u001b[39mon_batch_begin(xb, yb)\n\u001b[0;32m--> 101\u001b[0m     loss \u001b[39m=\u001b[39m loss_batch(learn\u001b[39m.\u001b[39;49mmodel, xb, yb, learn\u001b[39m.\u001b[39;49mloss_func, learn\u001b[39m.\u001b[39;49mopt, cb_handler)\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m cb_handler\u001b[39m.\u001b[39mon_batch_end(loss): \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cb_handler\u001b[39m.\u001b[39mskip_validate \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m learn\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mempty_val:\n",
      "File \u001b[0;32m~/anaconda3/envs/pssrMichael/lib/python3.10/site-packages/fastai/basic_train.py:35\u001b[0m, in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     33\u001b[0m     loss,skip_bwd \u001b[39m=\u001b[39m cb_handler\u001b[39m.\u001b[39mon_backward_begin(loss)\n\u001b[1;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_bwd:                     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cb_handler\u001b[39m.\u001b[39mon_backward_end(): opt\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cb_handler\u001b[39m.\u001b[39mon_step_end():     opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     38\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/anaconda3/envs/pssrMichael/lib/python3.10/site-packages/fastai/callback.py:57\u001b[0m, in \u001b[0;36mOptimWrapper.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m pg2[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]: p\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mmul_(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m wd\u001b[39m*\u001b[39mlr)\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_val(\u001b[39m'\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m'\u001b[39m, listify(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wd))\n\u001b[0;32m---> 57\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt\u001b[39m.\u001b[39;49mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/pssrMichael/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/pssrMichael/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/pssrMichael/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/pssrMichael/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/anaconda3/envs/pssrMichael/lib/python3.10/site-packages/torch/optim/adam.py:395\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    393\u001b[0m     param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom)\n\u001b[1;32m    394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 395\u001b[0m     step \u001b[39m=\u001b[39m step_t\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    397\u001b[0m     bias_correction1 \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m step\n\u001b[1;32m    398\u001b[0m     bias_correction2 \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m step\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if save_name is not load_name:\n",
    "    learn.save(save_name)\n",
    "    learn = learn.load(save_name)\n",
    "    print(f'copied {load_name} to {save_name}')\n",
    "\n",
    "print(int(cycles / 5))\n",
    "for i in range(5):\n",
    "    learn.fit_one_cycle(int(cycles / 5), lr)\n",
    "    learn.save(save_name)\n",
    "    print(f'save #{i}')\n",
    "    print(f'saved: {save_name}')\n",
    "    learn.export(pickle_models/f'{save_name}_{size}.pkl')\n",
    "    print('exported')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40JlBOoPswZQ"
   },
   "source": [
    "## **Export Trained PSSR Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrEFKkeO1xbD",
    "outputId": "34d3f8ef-7b09-4c5b-a9c8-96cdbd05e2cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: scale4_tile128_size512_epoch75_lr5e-4\n",
      "exported\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhrmu1RrtIL_"
   },
   "source": [
    "# **PSSR 04 - Inference**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGYno9rvtXGv"
   },
   "source": [
    "## **Specify Your Model and Test Data - need your input**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "wCEKqMH4tN_c"
   },
   "outputs": [],
   "source": [
    "# Modify accordingly\n",
    "model_name = 'scale4_tile128_size512_epoch100_lr8e-4_512'\n",
    "testset_name = '10HR'\n",
    "use_tiles = True\n",
    "mode = 'I' #Param(\"L or RGBA\", str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URfJNm9Etkip"
   },
   "source": [
    "## **Prepare for Inference**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQoUz-2ctnce",
    "outputId": "88e1cf6b-1dae-439f-c05a-817678ae4d40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale4_tile128_size512_epoch100_lr8e-4_512 model is being used.\n"
     ]
    }
   ],
   "source": [
    "# Prepare model\n",
    "test_path = Path(root_path)/'stats'\n",
    "model_name = model_name\n",
    "model_dir = test_path/'models'\n",
    "print(f'{model_name} model is being used.')\n",
    "\n",
    "# Prepare data\n",
    "testset_name = testset_name\n",
    "src_dir = test_path/'LR'/testset_name\n",
    "out_dir = test_path/'LR-PSSR'/testset_name\n",
    "out_dir = ensure_folder(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbeYEfM5tsX-"
   },
   "source": [
    "## **Inference**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cellView": "form",
    "id": "IP9EHOUNtyTi"
   },
   "outputs": [],
   "source": [
    "#@title process_czi\n",
    "\n",
    "def process_czi(fn, processor, proc_func, out_fn, n_depth=1, n_time=1, mode='L'):\n",
    "    stats = []\n",
    "    with czifile.CziFile(fn) as czi_f:\n",
    "        proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "        channels = proc_shape['C']\n",
    "        depths = proc_shape['Z']\n",
    "        times = proc_shape['T']\n",
    "        x, y = proc_shape['X'], proc_shape['Y']\n",
    "\n",
    "        data = czi_f.asarray().astype(np.float32)\n",
    "        data, img_info = img_to_float(data)\n",
    "\n",
    "        if depths < n_depth: return\n",
    "        if times < n_time: return\n",
    "\n",
    "        if n_depth > 1: # this is busted\n",
    "            offset_frames = n_depth // 2\n",
    "            for c in range(channels):\n",
    "                for t in range(times):\n",
    "                    for z in range(offset_frames, depths - offset_frame):\n",
    "                        depth_slice = slice(z-offset_frames, z+offset_frame+1)\n",
    "                        idx = build_index(\n",
    "                            proc_axes, {\n",
    "                                'T': t,\n",
    "                                'C': c,\n",
    "                                'Z': depth_slice,\n",
    "                                'X': slice(0, x),\n",
    "                                'Y': slice(0, y)\n",
    "                        })\n",
    "                        img = data[idx].copy()\n",
    "                        tag = f'{c}_{t}_{z+offset_frames}_'\n",
    "\n",
    "                        save_name = f'{proc_name}_{item.stem}_{tag}'\n",
    "\n",
    "                        pred_img = proc_func(img, img_info=img_info, mode=mode)\n",
    "                        pred_img8 = (pred_img * np.iinfo(np.uint8).max).astype(np.uint8)\n",
    "                        PIL.Image.fromarray(pred_img8).save(out_fn)\n",
    "        elif n_time > 1:\n",
    "            offset_frames = n_time // 2\n",
    "            for c in range(channels):\n",
    "                for z in range(depths):\n",
    "                    imgs = []\n",
    "                    time_range = list(range(offset_frames, times - offset_frames))\n",
    "                    for t in progress_bar(time_range):\n",
    "                        time_slice = slice(t-offset_frames, t+offset_frames+1)\n",
    "                        idx = build_index(\n",
    "                            proc_axes, {\n",
    "                                'T': time_slice,\n",
    "                                'C': c,\n",
    "                                'Z': z,\n",
    "                                'X': slice(0, x),\n",
    "                                'Y': slice(0, y)\n",
    "                        })\n",
    "                        img = data[idx].copy()\n",
    "                        pred_img = proc_func(img, img_info=img_info, mode=mode)\n",
    "                        pred_img8 = (pred_img * np.iinfo(np.uint8).max).astype(np.uint8)\n",
    "                        imgs.append(pred_img8[None])\n",
    "\n",
    "                    all_y = np.concatenate(imgs)\n",
    "                    if processor!='bilinear':\n",
    "                        fldr_name = f'{out_fn.parent}/{processor}'\n",
    "                    else:\n",
    "                        fldr_name = out_fn.parent.parent.parent/processor/out_fn.parent.stem\n",
    "                    save_name = f'{fn.stem}_{processor}.tif'\n",
    "                    if c > 1 or z > 1:\n",
    "                        fldr_name = fldr_name/f'{c}_{z}'\n",
    "                    out_fldr = ensure_folder(fldr_name)\n",
    "\n",
    "                    if all_y.size < 4e9:\n",
    "                        imageio.mimwrite(out_fldr/save_name, all_y)\n",
    "                    else:\n",
    "                        imageio.mimwrite(out_fldr/save_name, all_y, bigtiff=True)\n",
    "        else:\n",
    "            imgs = []\n",
    "            for c in range(channels):\n",
    "                for z in range(depths):\n",
    "                    for t in range(times):\n",
    "                        idx = build_index(\n",
    "                            proc_axes, {\n",
    "                                'T': t,\n",
    "                                'C': c,\n",
    "                                'Z': z,\n",
    "                                'X': slice(0, x),\n",
    "                                'Y': slice(0, y)\n",
    "                        })\n",
    "                        img = data[idx].copy()\n",
    "                        pred_img = proc_func(img, img_info=img_info, mode=mode)\n",
    "                        pred_img8 = (pred_img * np.iinfo(np.uint8).max).astype(np.uint8)\n",
    "                        imgs.append(pred_img8[None])\n",
    "            all_y = np.concatenate(imgs)\n",
    "            if processor!='bilinear':\n",
    "                fldr_name = f'{out_fn.parent}/{processor}'\n",
    "            else:\n",
    "                fldr_name = out_fn.parent.parent.parent/processor/out_fn.parent.stem\n",
    "            save_name = f'{fn.stem}_{processor}.tif'\n",
    "            out_fldr = ensure_folder(fldr_name)\n",
    "\n",
    "            if all_y.size < 4e9:\n",
    "                imageio.mimwrite(out_fldr/save_name, all_y)\n",
    "            else:\n",
    "                imageio.mimwrite(out_fldr/save_name, all_y, bigtiff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "STCntdaYtwci"
   },
   "outputs": [],
   "source": [
    "def process_tif(fn, processor, proc_func, out_fn, n_depth=1, n_time=1, mode='L'):\n",
    "    with PIL.Image.open(fn) as img_tif:\n",
    "        n_frame = max(n_depth, n_time)\n",
    "        offset_frames = n_frame // 2\n",
    "\n",
    "        if n_frame > img_tif.n_frames:\n",
    "            if img_tif.n_frames == 1:\n",
    "                times = n_frame\n",
    "                img_tif = np.array(img_tif)\n",
    "                data = np.repeat(img_tif[None],5,axis=0).astype(np.float32)\n",
    "            else:\n",
    "                return []\n",
    "        else:\n",
    "            times = img_tif.n_frames\n",
    "            img_tifs = []\n",
    "            for i in range(times):\n",
    "                img_tif.seek(i)\n",
    "                img_tif.load()\n",
    "                img_tifs.append(np.array(img_tif).copy())\n",
    "            data = np.stack(img_tifs).astype(np.float32)\n",
    "\n",
    "        data, img_info = img_to_float(data)\n",
    "        img_tiffs = []\n",
    "        time_range = list(range(offset_frames, times - offset_frames))\n",
    "        for t in progress_bar(time_range):\n",
    "            time_slice = slice(t-offset_frames, t+offset_frames+1)\n",
    "            img = data[time_slice].copy()\n",
    "            pred_img = proc_func(img, img_info=img_info, mode=mode)\n",
    "            # pred_img32 = (pred_img * np.iinfo(np.int32).max).astype(np.int32)\n",
    "            pred_img32 = (pred_img * np.iinfo(np.int32).max).astype(np.int32)\n",
    "            img_tiffs.append(pred_img32[None])\n",
    "\n",
    "        imgs = np.concatenate(img_tiffs)\n",
    "        if processor!='bilinear':\n",
    "            fldr_name = f'{out_fn.parent}/{processor}'\n",
    "        else:\n",
    "            fldr_name = out_fn.parent.parent.parent/processor/out_fn.parent.stem\n",
    "        save_name = f'{fn.stem}_{processor}.tif'\n",
    "        out_fldr = ensure_folder(out_fn.parent/processor)\n",
    "\n",
    "        if imgs.size < 4e9:\n",
    "            imageio.mimwrite(out_fldr/save_name, imgs)\n",
    "        else:\n",
    "            imageio.mimwrite(out_fldr/save_name, imgs, bigtiff=True)\n",
    "\n",
    "def process_files(src_dir, out_dir, model_dir, processor, mode, use_tiles):\n",
    "    proc_map = {\n",
    "        '.tif': process_tif,\n",
    "        '.czi': process_czi\n",
    "    }\n",
    "\n",
    "\n",
    "    proc_func, num_chan = get_named_processor(processor, model_dir, use_tiles)\n",
    "    src_files = list(src_dir.glob('**/*.czi'))\n",
    "    src_files += list(src_dir.glob('**/*.tif'))\n",
    "\n",
    "    for fn in progress_bar(src_files):\n",
    "        out_fn = out_dir/fn.relative_to(src_dir)\n",
    "        ensure_folder(out_fn.parent)\n",
    "        file_proc = proc_map.get(fn.suffix, None)\n",
    "        if file_proc:\n",
    "            n_depth = n_time = 1\n",
    "            if 'z_' in processor: n_depth = num_chan\n",
    "            if 't_' in processor: n_time = num_chan\n",
    "            print('File being processed: ', fn)\n",
    "            file_proc(fn, processor, proc_func, out_fn, n_depth=n_depth, n_time=n_time, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "0-9WOfTkt8D1",
    "outputId": "03ea5b7e-c532-40c2-d143-a25d3fdcb6f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "process_files(src_dir, out_dir, model_dir, model_name, mode, use_tiles)\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "b4-r1gE7Iamv",
    "GMetHM56gMkf",
    "ZCG3IlyEjzBa",
    "CjDTzO01qx4k"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8299560a4fa47ee6a550bbeda4e8a1b4b006c163be4a9e8a3df50218eaf08eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
